# -*- coding: utf-8 -*-
"""Iris Flowers Classification ML Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LlfCLHH-J5HpiUgHBdlrGGf2Z8HMsJyS
"""

import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import load_iris

dataset = load_iris()

dataset

print(dataset.DESCR)

X = dataset.data

y = dataset.target

y

X

plt.plot(X[:, 0][y == 0] * X[:, 1][y == 0], X[:, 2][y == 0] * X[:, 3][y == 0], 'r.', label="Satosa")
plt.plot(X[:, 0][y == 1] * X[:, 1][y == 1], X[:, 2][y == 1] * X[:, 3][y == 1], 'g.', label="Virginica")
plt.plot(X[:, 0][y == 2] * X[:, 1][y == 2], X[:, 2][y == 2] * X[:, 3][y == 2], 'b.', label="Versicolour")
plt.legend()
plt.show()

fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.axis('equal')
l = ['Versicolor', 'Setosa', 'Virginica']
s = [50,50,50]
ax.pie(s, labels = l,autopct='%1.2f%%')
plt.show()

from sklearn.preprocessing import StandardScaler
X = StandardScaler().fit_transform(X)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)

model.score(X, y)

model.score(X_train, y_train)

model.score(X_test, y_test)

from sklearn.naive_bayes import GaussianNB
model2 = GaussianNB()
model2.fit(X_train, y_train)

model2.score(X, y)

model2.score(X_test, y_test)

from sklearn.ensemble import RandomForestClassifier
model3 = RandomForestClassifier()
model3.fit(X_train, y_train)

model3.score(X,y)

model3.score(X_test, y_test)

import pandas as pd
results = pd.DataFrame({
    'Model': ['Logistic Regression','Random Forest Classifier', 'Naive Bayes'],
    'Score': [0.955,0.953,0.993]})

result_df = results.sort_values(by='Score', ascending=False)
result_df = result_df.set_index('Score')
result_df.head(9)

# Hence I'll use Random Forest Classifier for train my model